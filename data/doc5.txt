Contextualized chunk embeddings, like Voyage AI’s voyage‑context‑3 model, are designed for retrieval systems that break long documents into smaller chunks. Instead of embedding each chunk in isolation, the model processes the entire document and injects global context into every chunk’s embedding. This technique captures fine‑grained details and broader document context simultaneously without the need for manual metadata augmentation or overlapping chunks. It improves chunk‑level and document‑level retrieval accuracy and allows the model to be used as a drop‑in replacement for standard embeddings.
